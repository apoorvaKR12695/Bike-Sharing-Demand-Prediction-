{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apoorvaKR12695/Bike-Sharing-Demand-Prediction-/blob/main/Bike_Sharing_Demand_Prediction_Apoorva_KR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Seoul Bike Sharing Demand Prediction </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b> The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.</b>\n",
        "\n",
        "\n",
        "### <b>Attribute Information: </b>\n",
        "\n",
        "* ### Date : year-month-day\n",
        "* ### Rented Bike count - Count of bikes rented at each hour\n",
        "* ### Hour - Hour of he day\n",
        "* ### Temperature-Temperature in Celsius\n",
        "* ### Humidity - %\n",
        "* ### Windspeed - m/s\n",
        "* ### Visibility - 10m\n",
        "* ### Dew point temperature - Celsius\n",
        "* ### Solar radiation - MJ/m2\n",
        "* ### Rainfall - mm\n",
        "* ### Snowfall - cm\n",
        "* ### Seasons - Winter, Spring, Summer, Autumn\n",
        "* ### Holiday - Holiday/No holiday\n",
        "* ### Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lcMmVQDG0jX"
      },
      "source": [
        "**Importing Modules**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoRWbiafHZ06"
      },
      "source": [
        "**looading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIYwrsQUHr0P"
      },
      "outputs": [],
      "source": [
        "#let's mount the google drive for import the dtaset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZUsR9bbG6ue"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Bike Sharing Demand Prediction -Apoorva KR/SeoulBikeData.csv', encoding= 'unicode_escape')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mComkuDiG6xR"
      },
      "outputs": [],
      "source": [
        "# Viewing the data of top 5 rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xb8GglnJ776"
      },
      "outputs": [],
      "source": [
        "# View the data of bottom 5 rows \n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAoPEHSqJ8HO"
      },
      "outputs": [],
      "source": [
        "#Getting the shape of dataset with rows and columns\n",
        "print(df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsoKBpjlKKMx"
      },
      "outputs": [],
      "source": [
        "#check details about the data set\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQI0Kj8DKKY4"
      },
      "outputs": [],
      "source": [
        "#Looking for the description of the dataset\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HxcM0cFKKcL"
      },
      "outputs": [],
      "source": [
        "#Getting all the columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKVhhQzkK0ad"
      },
      "source": [
        "there are 14 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uht7JezLPEOw"
      },
      "outputs": [],
      "source": [
        "# finding total no of rows in dataset\n",
        "print(\"The no of rows in the dataset is \",len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **preprocessing the dataset**\n"
      ],
      "metadata": {
        "id": "35Kg4c-ZgVlq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGsE8vumLD2o"
      },
      "source": [
        "**Checking for null values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT5X2kZpKKfj"
      },
      "outputs": [],
      "source": [
        "#count of missing values in each column.\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RHUYSBoLvpU"
      },
      "source": [
        "that there is no null values is our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4O79P_sPyuG"
      },
      "source": [
        "**checking duplicate values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pn-lpJOLeio"
      },
      "outputs": [],
      "source": [
        "# Checking Duplicate Values\n",
        "duplicates =len(df[df.duplicated()])\n",
        "print(duplicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2hcKF94Pt2_"
      },
      "source": [
        "there are no duplicate values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qqv7kdMSvt2"
      },
      "source": [
        "**convert the \"date\" column into 3 different columns i.e \"year\",\"month\",\"day\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1RgqR72dIBk"
      },
      "outputs": [],
      "source": [
        "import datetime as dt\n",
        "df['date'] = df['Date'].apply(lambda x: dt.datetime.strptime(x,\"%d/%m/%Y\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIPPmjc7dgQs"
      },
      "outputs": [],
      "source": [
        "df['year'] = df['date'].dt.year\n",
        "df['month'] = df['date'].dt.month\n",
        "\n",
        "df['day'] = df['date'].dt.day_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECDpPiHBQMV1"
      },
      "outputs": [],
      "source": [
        "#creating a new column of \"weekdays_weekend\" and drop the column \"Date\",\"day\",\"year\"\n",
        "df['week']=df['day'].apply(lambda x : \"weekend\" if x=='Saturday' or x=='Sunday' else \"weekday\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afkeCFOpRvwP"
      },
      "outputs": [],
      "source": [
        "# checking no of years\n",
        "df['week'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbsPuo0mhYUS"
      },
      "outputs": [],
      "source": [
        "df=df.drop(columns=['date','day','year'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "H5WiwPiSeuot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So I convert the \"date\" column into 3 different column i.e \"year\",\"month\",\"day\".\n",
        "The \"year\" column in our data set is basically contain the 2 unique number contains the details of from 2017 december to 2018 november so if i consider this is a one year then we don't need the \"year\" column so we drop it.\n",
        "The other column \"day\", it contains the details about the each day of the month, for our relevence we don't need each day of each month data but we need the data about, if a day is a weekday or a weekend so we convert it into this format and drop the \"day\" column."
      ],
      "metadata": {
        "id": "7_ZRvznceoeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the int64 column into catagory column\n",
        "cols=['Hour','month','week']\n",
        "for col in cols:\n",
        "  df[col]=df[col].astype('category')"
      ],
      "metadata": {
        "id": "x-fj-RlBgQMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "xEvQsFLfgQp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slR3etQNhIKa"
      },
      "outputs": [],
      "source": [
        "#Heatmap for co-relation in features\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation between all the vaibles', size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above experiment i can conclude that Temperature and Dew point temperature(°C) has the high correlation . we drop this column then it dont affects the outcome of our analysis"
      ],
      "metadata": {
        "id": "aFSDHOCqkN8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGt2MEJShIS2"
      },
      "outputs": [],
      "source": [
        "df.drop(columns= ['Dew point temperature(°C)'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bvnu2I4UfiDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A5dPgpEbfiGr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": " Bike Sharing Demand Prediction - Apoorva KR.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}